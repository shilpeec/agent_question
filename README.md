# agent_question

This project is a Chrome Extension + FastAPI backend that helps students quickly find answers to Science questions. It uses a two-level system:

Memory Lookup: Searches in a local database (JSON file).

LLM Fallback: If no match is found, it queries Google Gemini for an answer.

Every response includes an agentic trace (Perception â†’ Memory â†’ Decision â†’ Action â†’ Observation) for transparency and learning insights.

ğŸ”§ Features

ğŸ§  Searches known questions from local memory

ğŸ¤– Falls back to LLM when memory fails

ğŸ” Shows how the answer was derived (agent trace)

âš™ï¸ Chrome extension interface

ğŸ§ª Includes a CLI script for testing

Answermethirduc/
â”œâ”€â”€ my_extension/
â”‚   â”œâ”€â”€ popup.html            # Extension popup UI
â”‚   â”œâ”€â”€ popup.js              # Logic for sending query to background
â”‚   â”œâ”€â”€ background.js         # Chrome service worker to handle API requests
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ questions.json    # Local memory of questions
â”œâ”€â”€ backend_files/
â”‚   â”œâ”€â”€ memory.py             # Loads local questions into Paper object
â”‚   â”œâ”€â”€ models.py             # Pydantic models for Question, Paper, etc.
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ system_prompt.txt     # Prompt template for LLM
â”œâ”€â”€ agent.py                  # AgenticWorkflow class (LLM handler)
â”œâ”€â”€ server.py                 # FastAPI backend server
â”œâ”€â”€ main.py                   # Optional script to run the logic in CLI
â”œâ”€â”€ .env                      # Gemini API key
â””â”€â”€ README.md                 # You're here!
